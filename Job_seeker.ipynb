{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3680f1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.5.230:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "# app.py\n",
    "import time, random, os, json\n",
    "import requests, pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from flask import Flask, request, render_template_string, send_file\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "HTML = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "  <meta charset=\"UTF-8\">\n",
    "  <title>Real-Time Job Trend Analyzer</title>\n",
    "  <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "  <style>\n",
    "    body { font-family: Arial; max-width: 1000px; margin: 20px auto; }\n",
    "    form { margin-bottom: 20px; }\n",
    "    input, button { padding: 8px; font-size: 1rem; }\n",
    "    .chart { margin-top: 30px; }\n",
    "    table { width: 100%; border-collapse: collapse; margin-top: 30px; }\n",
    "    th, td { border: 1px solid #ccc; padding: 6px; text-align: left; }\n",
    "    th { background: #f4f4f4; }\n",
    "    .jobs-list { max-height: 300px; overflow: auto; }\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "  <h1>Real-Time Job Trend Analyzer</h1>\n",
    "  <form method=\"POST\" action=\"/\">\n",
    "    <input name=\"keyword\" placeholder=\"Keyword (e.g. Data Analyst)\" value=\"{{ keyword }}\" required>\n",
    "    <button type=\"submit\">Scrape & Analyze Now</button>\n",
    "  </form>\n",
    "\n",
    "  {% if error %}\n",
    "    <p style=\"color:red\">{{ error }}</p>\n",
    "  {% endif %}\n",
    "\n",
    "  {% if count %}\n",
    "    <p><strong>Total jobs scraped:</strong> {{ count }}</p>\n",
    "\n",
    "    <div id=\"titles\" class=\"chart\"></div>\n",
    "    <div id=\"skills\" class=\"chart\"></div>\n",
    "    <div id=\"cities\" class=\"chart\"></div>\n",
    "    <div id=\"trends\" class=\"chart\"></div>\n",
    "\n",
    "    <script>\n",
    "      Plotly.newPlot('titles', {{ plots.titles|safe }});\n",
    "      Plotly.newPlot('skills', {{ plots.skills|safe }});\n",
    "      Plotly.newPlot('cities', {{ plots.cities|safe }});\n",
    "      Plotly.newPlot('trends', {{ plots.trends|safe }});\n",
    "    </script>\n",
    "\n",
    "    <h2>All Scraped Jobs</h2>\n",
    "    <div class=\"jobs-list\">\n",
    "      <table>\n",
    "        <tr>\n",
    "          <th>Title</th><th>Company</th><th>Location</th><th>Source</th><th>Date Posted</th>\n",
    "        </tr>\n",
    "        {% for job in jobs %}\n",
    "        <tr>\n",
    "          <td>{{ job.title }}</td>\n",
    "          <td>{{ job.company }}</td>\n",
    "          <td>{{ job.location }}</td>\n",
    "          <td>{{ job.source }}</td>\n",
    "          <td>{{ job.date_posted }}</td>\n",
    "        </tr>\n",
    "        {% endfor %}\n",
    "      </table>\n",
    "    </div>\n",
    "\n",
    "    <p><a href=\"/download\"><button>Download CSV</button></a></p>\n",
    "  {% endif %}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "INDEED_HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "}\n",
    "DELAY = (1.0, 2.5)\n",
    "\n",
    "def parse_indeed_date(date_str):\n",
    "    if not date_str:\n",
    "        return None\n",
    "    date_str = date_str.lower().replace(\"posted\", \"\").replace(\"active\", \"\").strip()\n",
    "    today = datetime.today()\n",
    "    try:\n",
    "        if \"today\" in date_str or \"just posted\" in date_str:\n",
    "            return today.date()\n",
    "        elif \"+\" in date_str:\n",
    "            days_ago = int(date_str.split(\"+\")[0].strip())\n",
    "            return (today - timedelta(days=days_ago)).date()\n",
    "        elif \"day\" in date_str:\n",
    "            parts = date_str.split()\n",
    "            days_ago = int(parts[0])\n",
    "            return (today - timedelta(days=days_ago)).date()\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def scrape_indeed(keyword, max_pages=5):\n",
    "    jobs, session = [], requests.Session()\n",
    "    session.headers.update(INDEED_HEADERS)\n",
    "    kw = requests.utils.quote(keyword)\n",
    "    for page in range(max_pages):\n",
    "        url = f\"https://www.indeed.com/jobs?q={kw}&start={page*10}\"\n",
    "        try:\n",
    "            r = session.get(url, timeout=10)\n",
    "            if r.status_code != 200:\n",
    "                break\n",
    "            soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "            if \"captcha\" in soup.text.lower():\n",
    "                print(\"CAPTCHA detected on Indeed\")\n",
    "                break\n",
    "            cards = soup.find_all(\"div\", class_=\"job_seen_beacon\")\n",
    "            if not cards:\n",
    "                break\n",
    "            for c in cards:\n",
    "                try:\n",
    "                    t = c.find(\"h2\", class_=\"jobTitle\").get_text(strip=True)\n",
    "                    co = c.find(\"span\", class_=\"companyName\").get_text(strip=True)\n",
    "                    lo = c.find(\"div\", class_=\"companyLocation\").get_text(strip=True)\n",
    "                    date_span = c.find(\"span\", class_=\"date\")\n",
    "                    date_text = date_span.get_text(strip=True) if date_span else \"\"\n",
    "                    parsed_date = parse_indeed_date(date_text)\n",
    "                    jobs.append({\n",
    "                        \"title\": t,\n",
    "                        \"company\": co,\n",
    "                        \"location\": lo,\n",
    "                        \"source\": \"Indeed\",\n",
    "                        \"date_posted\": parsed_date.isoformat() if parsed_date else \"\"\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "            time.sleep(random.uniform(*DELAY))\n",
    "        except Exception as e:\n",
    "            break\n",
    "    return jobs\n",
    "\n",
    "def scrape_linkedin(keyword, max_scroll=3):\n",
    "    opts = Options()\n",
    "    opts.add_argument(\"--headless\")\n",
    "    opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    opts.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "    opts.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    opts.add_experimental_option(\"useAutomationExtension\", False)\n",
    "    \n",
    "    driver = webdriver.Chrome(options=opts)\n",
    "    driver.get(f\"https://www.linkedin.com/jobs/search/?keywords={requests.utils.quote(keyword)}\")\n",
    "    \n",
    "    for _ in range(max_scroll):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(random.uniform(1.5, 3.0))\n",
    "        try:\n",
    "            see_more_button = driver.find_element(By.XPATH, \"//button[contains(@aria-label, 'See more jobs')]\")\n",
    "            driver.execute_script(\"arguments[0].click();\", see_more_button)\n",
    "            time.sleep(1)\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "\n",
    "    jobs = []\n",
    "    cards = driver.find_elements(By.CSS_SELECTOR, \"li.base-card\")\n",
    "    for c in cards:\n",
    "        try:\n",
    "            title = c.find_element(By.CSS_SELECTOR, \"h3.base-search-card__title\").text.strip()\n",
    "            company = c.find_element(By.CSS_SELECTOR, \"h4.base-search-card__subtitle\").text.strip()\n",
    "            loc = c.find_element(By.CSS_SELECTOR, \"span.job-search-card__location\").text.strip()\n",
    "            time_element = c.find_element(By.CSS_SELECTOR, \"time\")\n",
    "            date_posted = time_element.get_attribute(\"datetime\")[:10] if time_element else \"\"\n",
    "            jobs.append({\n",
    "                \"title\": title,\n",
    "                \"company\": company,\n",
    "                \"location\": loc,\n",
    "                \"source\": \"LinkedIn\",\n",
    "                \"date_posted\": date_posted\n",
    "            })\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    driver.quit()\n",
    "    return jobs\n",
    "\n",
    "def analyze_jobs(df):\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date_posted\"], errors=\"coerce\")\n",
    "    titles = df[\"title\"].value_counts().head(5)\n",
    "    skills = pd.Series(sum([t.lower().split() for t in df[\"title\"]], [])).value_counts().head(10)\n",
    "    cities = df[\"location\"].value_counts().head(5)\n",
    "    trends = df[\"date\"].dt.date.value_counts().sort_index()\n",
    "    return titles, skills, cities, trends\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\",\"POST\"])\n",
    "def index():\n",
    "    error = \"\"\n",
    "    plots = {}\n",
    "    jobs = []\n",
    "    count = 0\n",
    "    keyword = \"\"\n",
    "    if request.method == \"POST\":\n",
    "        keyword = request.form[\"keyword\"].strip()\n",
    "        if not keyword:\n",
    "            error = \"Please enter a keyword.\"\n",
    "        else:\n",
    "            try:\n",
    "                indeed_jobs = scrape_indeed(keyword)\n",
    "                linkedin_jobs = scrape_linkedin(keyword)\n",
    "                jobs = indeed_jobs + linkedin_jobs\n",
    "                if not jobs:\n",
    "                    error = \"No jobs found.\"\n",
    "                else:\n",
    "                    df = pd.DataFrame(jobs)\n",
    "                    df.to_csv(\"jobs.csv\", index=False)\n",
    "                    count = len(df)\n",
    "                    t, s, c, tr = analyze_jobs(df)\n",
    "                    \n",
    "                    # Prepare data for visualizations\n",
    "                    titles_df = t.reset_index()\n",
    "                    titles_df.columns = ['title', 'count']\n",
    "                    skills_df = s.reset_index()\n",
    "                    skills_df.columns = ['skill', 'count']\n",
    "                    cities_df = c.reset_index()\n",
    "                    cities_df.columns = ['city', 'count']\n",
    "                    trends_df = tr.reset_index()\n",
    "                    trends_df.columns = ['date', 'count']\n",
    "\n",
    "                    # Create visualizations\n",
    "                    fig1 = px.bar(titles_df, x='count', y='title', \n",
    "                                title=\"Top 5 Job Titles\", labels={'count': 'Number of Jobs', 'title': 'Job Title'})\n",
    "                    fig2 = px.bar(skills_df, x='count', y='skill', \n",
    "                                title=\"Top 10 Skills\", labels={'count': 'Frequency', 'skill': 'Skill'})\n",
    "                    fig3 = px.bar(cities_df, x='count', y='city', \n",
    "                                title=\"Top 5 Locations\", labels={'count': 'Number of Jobs', 'city': 'Location'})\n",
    "                    fig4 = px.line(trends_df, x='date', y='count', \n",
    "                                title=\"Posting Trends\", labels={'date': 'Date', 'count': 'Number of Postings'})\n",
    "\n",
    "                    plots = {\n",
    "                        \"titles\": json.dumps(fig1, cls=plotly.utils.PlotlyJSONEncoder),\n",
    "                        \"skills\": json.dumps(fig2, cls=plotly.utils.PlotlyJSONEncoder),\n",
    "                        \"cities\": json.dumps(fig3, cls=plotly.utils.PlotlyJSONEncoder),\n",
    "                        \"trends\": json.dumps(fig4, cls=plotly.utils.PlotlyJSONEncoder),\n",
    "                    }\n",
    "            except Exception as e:\n",
    "                error = f\"Error occurred during scraping: {str(e)}\"\n",
    "    return render_template_string(HTML, error=error, plots=plots, jobs=jobs, count=count, keyword=keyword)\n",
    "\n",
    "@app.route(\"/download\")\n",
    "def download():\n",
    "    if os.path.exists(\"jobs.csv\"):\n",
    "        return send_file(\"jobs.csv\", as_attachment=True)\n",
    "    return \"No CSV found. Please scrape jobs first.\", 404\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5000, debug=False, use_reloader=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
